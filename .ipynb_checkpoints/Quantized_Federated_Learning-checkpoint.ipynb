{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning Model with Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model size: 23520326 parameters\n",
      "Memory occupied by float32 parameters: 94081304 bytes\n",
      "Memory occupied by int8 parameters: 23520326 bytes\n",
      "Memory saved by using int8 parameters: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import copy\n",
    "\n",
    "# Load the saved model\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 6)  # Change the output layer to match your task\n",
    "\n",
    "# Load the model state_dict from the saved .pth file\n",
    "model.load_state_dict(torch.load('updated_global_model_1.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create a new instance of the model and load the state_dict to mimic clone\n",
    "quantized_model = models.resnet50(pretrained=False)\n",
    "quantized_model.fc = torch.nn.Linear(quantized_model.fc.in_features, 6)  # Change the output layer to match your task\n",
    "quantized_model.load_state_dict(copy.deepcopy(model.state_dict()))\n",
    "\n",
    "# Set the cloned model to evaluation mode\n",
    "quantized_model.eval()\n",
    "\n",
    "# Quantize the weights of the cloned model to -1 or 1\n",
    "for param in model.parameters():\n",
    "    param.data = torch.sign(param.data)\n",
    "\n",
    "# Calculate the number of parameters in the original and quantized models\n",
    "quantized_model_num_params = sum(p.numel() for p in quantized_model.parameters())\n",
    "\n",
    "torch.save(quantized_model.state_dict(), \"binary_quantized_model.pth\")\n",
    "print(f\"Quantized model size: {quantized_model_num_params} parameters\")\n",
    "\n",
    "float32_param_size = quantized_model_num_params * 4  # 4 bytes per float32 parameter\n",
    "print(f\"Memory occupied by float32 parameters: {float32_param_size} bytes\")\n",
    "\n",
    "int8_param_size = quantized_model_num_params * 1  # 1 byte per int8 parameter\n",
    "print(f\"Memory occupied by int8 parameters: {int8_param_size} bytes\")\n",
    "\n",
    "saved_percentage = ((float32_param_size - int8_param_size) / float32_param_size) * 100\n",
    "print(f\"Memory saved by using int8 parameters: {saved_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "\n",
    "def test_model(data_dir, model_name):\n",
    "    import torch\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "    import torch.nn as nn\n",
    "\n",
    "    # Define paths to your test dataset folder\n",
    "    test_data_dir = data_dir  # Update with your test dataset path\n",
    "\n",
    "    # Define transformations for testing (similar to training)\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Load the test dataset using ImageFolder with the defined transformations\n",
    "    test_dataset = datasets.ImageFolder(root=test_data_dir, transform=test_transforms)\n",
    "\n",
    "    # Define the test dataloader\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Load the model architecture\n",
    "    model = resnet50(weights=None)\n",
    "    model.eval()\n",
    "\n",
    "    # Replace the final fully connected layer for transfer learning with the same num_classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    num_classes = 6\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Load the trained weights from the saved .pth file\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    model.eval()\n",
    "\n",
    "    # Move the model to GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Evaluate the model on the test dataset for both top-1 and top-3 accuracy\n",
    "    correct_top1 = 0\n",
    "    correct_top3 = 0\n",
    "\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.topk(outputs, 3, dim=1)  # Get top-3 predictions\n",
    "            total += labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if labels[i] == preds[i, 0]:  # Check top-1 accuracy\n",
    "                    correct_top1 += 1\n",
    "                if labels[i] in preds[i]:  # Check top-3 accuracy\n",
    "                    correct_top3 += 1\n",
    "\n",
    "    top1_accuracy = 100 * correct_top1 / total\n",
    "    top3_accuracy = 100 * correct_top3 / total\n",
    "    print(f'Top-1 Accuracy on the {data_dir} dataset: {top1_accuracy:.2f}%')\n",
    "    print(f'Top-3 Accuracy on the {data_dir} dataset: {top3_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 99.50%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 99.98%\n"
     ]
    }
   ],
   "source": [
    "test_model('../Dataset/validation_data', \"binary_quantized_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy on the ../Dataset/test_data dataset: 99.44%\n",
      "Top-3 Accuracy on the ../Dataset/test_data dataset: 99.98%\n"
     ]
    }
   ],
   "source": [
    "test_model('../Dataset/test_data', \"binary_quantized_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
