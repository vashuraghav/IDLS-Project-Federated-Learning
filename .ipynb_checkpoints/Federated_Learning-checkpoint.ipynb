{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = ['../Dataset/5_percent_data', '../Dataset/10_percent_data', '../Dataset/15_percent_data', '../Dataset/20_percent_data', '../Dataset/25_percent_data']\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "dataset_5 = datasets.ImageFolder(root=dataset_paths[0], transform=train_transforms)\n",
    "dataset_10 = datasets.ImageFolder(root=dataset_paths[1], transform=train_transforms)\n",
    "dataset_15 = datasets.ImageFolder(root=dataset_paths[2], transform=train_transforms)\n",
    "dataset_20 = datasets.ImageFolder(root=dataset_paths[3], transform=train_transforms)\n",
    "dataset_25 = datasets.ImageFolder(root=dataset_paths[4], transform=train_transforms)\n",
    "\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(global_model_name, train_dataset, output_model_name):\n",
    "    # Load the model architecture\n",
    "    model = resnet50(weights=None)\n",
    "    model.eval()\n",
    "\n",
    "    # Replace the final fully connected layer for transfer learning with the same num_classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    num_classes = 6\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Load the trained weights from the saved .pth file\n",
    "    model.load_state_dict(torch.load(global_model_name))\n",
    "    model.eval()\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Move the model to GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    # Train the model\n",
    "    start_time = time.time()  # Record the end time of the epoch\n",
    "    num_epochs = 20  # You can change this\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f}')\n",
    "        if epoch_loss <= 0.01:\n",
    "            print(\" Early Stopping \")\n",
    "            break\n",
    "    end_time = time.time()  # Record the end time of the epoch\n",
    "    print(\" Training Time \", end_time - start_time)\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), output_model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data_dir, model_name):\n",
    "    import torch\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "    import torch.nn as nn\n",
    "\n",
    "    # Define paths to your test dataset folder\n",
    "    test_data_dir = data_dir  # Update with your test dataset path\n",
    "\n",
    "    # Define transformations for testing (similar to training)\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Load the test dataset using ImageFolder with the defined transformations\n",
    "    test_dataset = datasets.ImageFolder(root=test_data_dir, transform=test_transforms)\n",
    "\n",
    "    # Define the test dataloader\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Load the model architecture\n",
    "    model = resnet50(weights=None)\n",
    "    model.eval()\n",
    "\n",
    "    # Replace the final fully connected layer for transfer learning with the same num_classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    num_classes = 6\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Load the trained weights from the saved .pth file\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    model.eval()\n",
    "\n",
    "    # Move the model to GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Evaluate the model on the test dataset for both top-1 and top-3 accuracy\n",
    "    correct_top1 = 0\n",
    "    correct_top3 = 0\n",
    "\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.topk(outputs, 3, dim=1)  # Get top-3 predictions\n",
    "            total += labels.size(0)\n",
    "            for i in range(labels.size(0)):\n",
    "                if labels[i] == preds[i, 0]:  # Check top-1 accuracy\n",
    "                    correct_top1 += 1\n",
    "                if labels[i] in preds[i]:  # Check top-3 accuracy\n",
    "                    correct_top3 += 1\n",
    "\n",
    "    top1_accuracy = 100 * correct_top1 / total\n",
    "    top3_accuracy = 100 * correct_top3 / total\n",
    "    print(f'Top-1 Accuracy on the {data_dir} dataset: {top1_accuracy:.2f}%')\n",
    "    print(f'Top-3 Accuracy on the {data_dir} dataset: {top3_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_global_model(model_5, model_10, model_15, model_20, model_25, global_model, iteration):\n",
    "    state_dict_5 = model_5.state_dict()\n",
    "    state_dict_10 = model_10.state_dict()\n",
    "    state_dict_15 = model_15.state_dict()\n",
    "    state_dict_20 = model_20.state_dict()\n",
    "    state_dict_25 = model_25.state_dict()\n",
    "\n",
    "    \n",
    "    for key in global_model.state_dict():\n",
    "        w1 = state_dict_5[key]\n",
    "        w2 = state_dict_10[key]\n",
    "        w3 = state_dict_15[key]\n",
    "        w4 = state_dict_20[key]\n",
    "        w5 = state_dict_25[key]\n",
    "\n",
    "    \n",
    "        updated_weight = (w1 * 1 + w2 * 2 + w3 * 3 + w4 * 4 + w5 * 5) / 15\n",
    "        global_model.state_dict()[key].copy_(updated_weight)\n",
    "    global_model_name = 'updated_global_model_' + str(iteration) +'.pth'\n",
    "    torch.save(global_model.state_dict(), global_model_name)\n",
    "    \n",
    "    return global_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 20.23%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 56.12%\n",
      "Iteration:  1\n",
      " Global model  trained_global_model.pth\n",
      " Model :  trained_model_5_1.pth\n",
      "Epoch 1/20 | Loss: 1.0908\n",
      "Epoch 2/20 | Loss: 0.5128\n",
      "Epoch 3/20 | Loss: 0.3684\n",
      "Epoch 4/20 | Loss: 0.3031\n",
      "Epoch 5/20 | Loss: 0.2556\n",
      "Epoch 6/20 | Loss: 0.2221\n",
      "Epoch 7/20 | Loss: 0.1938\n",
      "Epoch 8/20 | Loss: 0.1770\n",
      "Epoch 9/20 | Loss: 0.1698\n",
      "Epoch 10/20 | Loss: 0.1660\n",
      "Epoch 11/20 | Loss: 0.1493\n",
      "Epoch 12/20 | Loss: 0.1460\n",
      "Epoch 13/20 | Loss: 0.1332\n",
      "Epoch 14/20 | Loss: 0.1241\n",
      "Epoch 15/20 | Loss: 0.1327\n",
      "Epoch 16/20 | Loss: 0.1335\n",
      "Epoch 17/20 | Loss: 0.1097\n",
      "Epoch 18/20 | Loss: 0.1118\n",
      "Epoch 19/20 | Loss: 0.1103\n",
      "Epoch 20/20 | Loss: 0.1038\n",
      " Training Time  69.53484010696411\n",
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 98.86%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 99.80%\n",
      " Model :  trained_model_10_1.pth\n",
      "Epoch 1/20 | Loss: 0.8849\n",
      "Epoch 2/20 | Loss: 0.3878\n",
      "Epoch 3/20 | Loss: 0.2823\n",
      "Epoch 4/20 | Loss: 0.2301\n",
      "Epoch 5/20 | Loss: 0.2100\n",
      "Epoch 6/20 | Loss: 0.1798\n",
      "Epoch 7/20 | Loss: 0.1659\n",
      "Epoch 8/20 | Loss: 0.1579\n",
      "Epoch 9/20 | Loss: 0.1425\n",
      "Epoch 10/20 | Loss: 0.1336\n",
      "Epoch 11/20 | Loss: 0.1296\n",
      "Epoch 12/20 | Loss: 0.1226\n",
      "Epoch 13/20 | Loss: 0.1164\n",
      "Epoch 14/20 | Loss: 0.1118\n",
      "Epoch 15/20 | Loss: 0.1054\n",
      "Epoch 16/20 | Loss: 0.1051\n",
      "Epoch 17/20 | Loss: 0.0980\n",
      "Epoch 18/20 | Loss: 0.0969\n",
      "Epoch 19/20 | Loss: 0.0919\n",
      "Epoch 20/20 | Loss: 0.0901\n",
      " Training Time  112.94255065917969\n",
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 99.24%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 99.98%\n",
      " Model :  trained_model_15_1.pth\n",
      "Epoch 1/20 | Loss: 0.7299\n",
      "Epoch 2/20 | Loss: 0.3009\n",
      "Epoch 3/20 | Loss: 0.2190\n",
      "Epoch 4/20 | Loss: 0.1863\n",
      "Epoch 5/20 | Loss: 0.1670\n",
      "Epoch 6/20 | Loss: 0.1462\n",
      "Epoch 7/20 | Loss: 0.1288\n",
      "Epoch 8/20 | Loss: 0.1219\n",
      "Epoch 9/20 | Loss: 0.1150\n",
      "Epoch 10/20 | Loss: 0.1075\n",
      "Epoch 11/20 | Loss: 0.1054\n",
      "Epoch 12/20 | Loss: 0.0982\n",
      "Epoch 13/20 | Loss: 0.0931\n",
      "Epoch 14/20 | Loss: 0.0900\n",
      "Epoch 15/20 | Loss: 0.0885\n",
      "Epoch 16/20 | Loss: 0.0881\n",
      "Epoch 17/20 | Loss: 0.0831\n",
      "Epoch 18/20 | Loss: 0.0809\n",
      "Epoch 19/20 | Loss: 0.0768\n",
      "Epoch 20/20 | Loss: 0.0745\n",
      " Training Time  168.6939103603363\n",
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 99.37%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 99.98%\n",
      " Model :  trained_model_20_1.pth\n",
      "Epoch 1/20 | Loss: 0.6615\n",
      "Epoch 2/20 | Loss: 0.2692\n",
      "Epoch 3/20 | Loss: 0.1916\n",
      "Epoch 4/20 | Loss: 0.1630\n",
      "Epoch 5/20 | Loss: 0.1429\n",
      "Epoch 6/20 | Loss: 0.1272\n",
      "Epoch 7/20 | Loss: 0.1205\n",
      "Epoch 8/20 | Loss: 0.1040\n",
      "Epoch 9/20 | Loss: 0.1024\n",
      "Epoch 10/20 | Loss: 0.0991\n",
      "Epoch 11/20 | Loss: 0.0943\n",
      "Epoch 12/20 | Loss: 0.0921\n",
      "Epoch 13/20 | Loss: 0.0836\n",
      "Epoch 14/20 | Loss: 0.0812\n",
      "Epoch 15/20 | Loss: 0.0820\n",
      "Epoch 16/20 | Loss: 0.0710\n",
      "Epoch 17/20 | Loss: 0.0719\n",
      "Epoch 18/20 | Loss: 0.0724\n",
      "Epoch 19/20 | Loss: 0.0670\n",
      "Epoch 20/20 | Loss: 0.0654\n",
      " Training Time  219.90845322608948\n",
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 99.40%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 99.95%\n",
      " Model :  trained_model_25_1.pth\n",
      "Epoch 1/20 | Loss: 0.5731\n",
      "Epoch 2/20 | Loss: 0.2345\n",
      "Epoch 3/20 | Loss: 0.1713\n",
      "Epoch 4/20 | Loss: 0.1393\n",
      "Epoch 5/20 | Loss: 0.1232\n",
      "Epoch 6/20 | Loss: 0.1152\n",
      "Epoch 7/20 | Loss: 0.1039\n",
      "Epoch 8/20 | Loss: 0.0955\n",
      "Epoch 9/20 | Loss: 0.0873\n",
      "Epoch 10/20 | Loss: 0.0873\n",
      "Epoch 11/20 | Loss: 0.0837\n",
      "Epoch 12/20 | Loss: 0.0805\n",
      "Epoch 13/20 | Loss: 0.0775\n",
      "Epoch 14/20 | Loss: 0.0671\n",
      "Epoch 15/20 | Loss: 0.0678\n",
      "Epoch 16/20 | Loss: 0.0649\n",
      "Epoch 17/20 | Loss: 0.0649\n",
      "Epoch 18/20 | Loss: 0.0637\n",
      "Epoch 19/20 | Loss: 0.0629\n",
      "Epoch 20/20 | Loss: 0.0589\n",
      " Training Time  296.6254382133484\n",
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 99.60%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 99.98%\n",
      " Updated global Model :  updated_global_model_1.pth\n",
      "Top-1 Accuracy on the ../Dataset/validation_data dataset: 99.50%\n",
      "Top-3 Accuracy on the ../Dataset/validation_data dataset: 99.98%\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.eval()\n",
    "# Replace the final fully connected layer for transfer learning with the same num_classes\n",
    "num_ftrs = model.fc.in_features\n",
    "num_classes = 6\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "global_model_name = \"trained_global_model.pth\"\n",
    "torch.save(model.state_dict(), global_model_name)\n",
    "test_model('../Dataset/validation_data', global_model_name)\n",
    "\n",
    "global_model_name = \"trained_global_model.pth\"\n",
    "i = 0\n",
    "interval = 1\n",
    "for i in range(interval):\n",
    "    print(\"Iteration: \", i+1)\n",
    "    print(\" Global model \", global_model_name)\n",
    "    total_5 = len(dataset_5)\n",
    "    start_index_5 = (i*total_5)//interval\n",
    "    end_index_5 = min(total_5, ((i+1)*total_5)//interval)\n",
    "    portion_dataset_5 = torch.utils.data.Subset(dataset_5, list(range(start_index_5, end_index_5)))\n",
    "    model_name_5 = \"trained_model_5_\" + str(i+1) + \".pth\"\n",
    "    print(\" Model : \", model_name_5)\n",
    "    model_5 = train_model(global_model_name, portion_dataset_5, model_name_5)\n",
    "    test_model('../Dataset/validation_data', model_name_5)\n",
    "    \n",
    "    total_10 = len(dataset_10)\n",
    "    start_index_10 = (i*total_10)//interval\n",
    "    end_index_10 = min(total_10, ((i+1)*total_10)//interval)\n",
    "    portion_dataset_10 = torch.utils.data.Subset(dataset_10, list(range(start_index_10, end_index_10)))\n",
    "    model_name_10 = \"trained_model_10_\" + str(i+1) + \".pth\"\n",
    "    print(\" Model : \", model_name_10)\n",
    "    model_10 = train_model(global_model_name, portion_dataset_10, model_name_10)\n",
    "    test_model('../Dataset/validation_data', model_name_10)\n",
    "    \n",
    "    total_15 = len(dataset_15)\n",
    "    start_index_15 = (i*total_15)//interval\n",
    "    end_index_15 = min(total_15, ((i+1)*total_15)//interval)\n",
    "    portion_dataset_15 = torch.utils.data.Subset(dataset_15, list(range(start_index_15, end_index_15)))\n",
    "    model_name_15 = \"trained_model_15_\" + str(i+1) + \".pth\"\n",
    "    print(\" Model : \", model_name_15)\n",
    "    model_15 = train_model(global_model_name, portion_dataset_15, model_name_15)\n",
    "    test_model('../Dataset/validation_data', model_name_15)\n",
    "    \n",
    "    total_20 = len(dataset_20)\n",
    "    start_index_20 = (i*total_20)//interval\n",
    "    end_index_20 = min(total_20, ((i+1)*total_20)//interval)\n",
    "    portion_dataset_20 = torch.utils.data.Subset(dataset_20, list(range(start_index_20, end_index_20)))\n",
    "    model_name_20 = \"trained_model_20_\" + str(i+1) + \".pth\"\n",
    "    print(\" Model : \", model_name_20)\n",
    "    model_20 = train_model(global_model_name, portion_dataset_20, model_name_20)\n",
    "    test_model('../Dataset/validation_data', model_name_20)\n",
    "    \n",
    "    total_25 = len(dataset_25)\n",
    "    start_index_25 = (i*total_25)//interval\n",
    "    end_index_25 = min(total_25, ((i+1)*total_25)//interval)\n",
    "    portion_dataset_25 = torch.utils.data.Subset(dataset_25, list(range(start_index_25, end_index_25)))\n",
    "    model_name_25 = \"trained_model_25_\" + str(i+1) + \".pth\"\n",
    "    print(\" Model : \", model_name_25)\n",
    "    model_25 = train_model(global_model_name, portion_dataset_25, model_name_25)\n",
    "    test_model('../Dataset/validation_data', model_name_25)\n",
    "    \n",
    "    ## Update global model\n",
    "    \n",
    "    # Load the model architecture\n",
    "    global_model = resnet50(weights=None)\n",
    "    global_model.eval()\n",
    "    \n",
    "\n",
    "    # Replace the final fully connected layer for transfer learning with the same num_classes\n",
    "    num_ftrs = global_model.fc.in_features\n",
    "    global_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Load the trained weights from the saved .pth file\n",
    "    global_model.load_state_dict(torch.load(global_model_name))\n",
    "    global_model.eval()\n",
    "    \n",
    "    global_model_name = update_global_model(model_5, model_10, model_15, model_20, model_25, global_model, i+1)\n",
    "    print(\" Updated global Model : \", global_model_name)\n",
    "    test_model('../Dataset/validation_data', global_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy on the ../Dataset/test_data dataset: 99.44%\n",
      "Top-3 Accuracy on the ../Dataset/test_data dataset: 99.98%\n"
     ]
    }
   ],
   "source": [
    "test_model('../Dataset/test_data', global_model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
